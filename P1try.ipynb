{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from operator import add, itemgetter\n",
    "import json\n",
    "from string import punctuation\n",
    "import math\n",
    "from pyspark.conf import SparkConf\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating count of words in all docs combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = pyspark.SparkContext('local',appName=\"DocClassification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = sc.textFile(\"/home/vyom/UGA/DSP/Project1/X_train_small.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sc.textFile(\"/home/vyom/UGA/DSP/Project1/y_train_small.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splt = documents.flatMap(lambda word: word.split())\n",
    "splt = splt.map(lambda word: word.lower())\n",
    "\n",
    "#Removing Punctuation\n",
    "splt = splt.map(lambda word: word.replace(\"&quot;\",\"\"))\n",
    "splt = splt.map(lambda word: word.replace(\"&amp;\",\"\"))\n",
    "cleanWords = splt.map(lambda word: word.strip(punctuation))\n",
    "cleanWords = cleanWords.filter(lambda word:len(word)>2)\n",
    "\n",
    "#Removing StopWord\n",
    "stopWordFile = sc.textFile(\"stopwords.txt\")\n",
    "stopWord = sc.broadcast(stopWordFile.collect())\n",
    "lessWords = cleanWords.filter(lambda x: x not in stopWord.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = cleanWords.map(lambda word : (word,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountinAllDocs = word.reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CountinAllDocs = CountinAllDocs.sortBy(lambda x: x[1],False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWords = sc.broadcast(CountinAllDocs.count())\n",
    "numDocs = sc.broadcast(documents.count())\n",
    "wordList = sc.broadcast(CountinAllDocs.keys().collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating term frequency in each doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripWord(x):\n",
    "    tempList =[]\n",
    "    for word in x:\n",
    "        word = word.replace(\"&quot\",\"\")\n",
    "        word = word.strip(punctuation)\n",
    "        if len(word)>0:\n",
    "            tempList.append(word)\n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripStopWord(x):\n",
    "    tempList =[]\n",
    "    for word in x:\n",
    "        if word not in stopWord.value:\n",
    "            tempList.append(word)\n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWord(x):\n",
    "    dictionary={}\n",
    "    for word in x:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = 1\n",
    "        else:\n",
    "            dictionary[word]+=1\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bagOfWords = documents.map(lambda word: word.lower().split())\n",
    "bagOfWords = bagOfWords.map(lambda x: stripWord(x))\n",
    "bagOfWords = bagOfWords.map(lambda x: stripStopWord(x))\n",
    "tf = bagOfWords.map(lambda x: countWord(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniques(x):\n",
    "    tempList=[]\n",
    "    for word in x:\n",
    "        if word not in tempList:\n",
    "            tempList.append(word);\n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueList = tf.map(lambda x: uniques(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeMap(x):\n",
    "    tempList = []\n",
    "    for word in x:\n",
    "        tempList.append((word,1))\n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurences = sc.parallelize(uniqueList.map(lambda x: initializeMap(x)).reduce(add))\n",
    "occurences = occurences.reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = occurences.map(lambda x: (x[0],math.log(numDocs.value/x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf2 = sc.broadcast(idf.collectAsMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTfidf(x):\n",
    "    tempDict={}\n",
    "    idfDict=idf2.value\n",
    "    for k,v in x.items():\n",
    "        tempDict[k] = v*idfDict[k]\n",
    "    return tempDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tf.map(lambda x: getTfidf(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tfidfSorted = tfidf.map(lambda x: sorted(x.items(), key=itemgetter(1), reverse = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating word probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "spltLabels = labels.map(lambda word: word.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeUnnecessary(label):\n",
    "    tempList=[]\n",
    "    for word in label:\n",
    "        if 'CAT' in word:\n",
    "            tempList.append(word)\n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "requiredLabels = spltLabels.map(lambda label: removeUnnecessary(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfDocs = sc.broadcast(len(requiredLabels.reduce(add)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsToUse = sc.broadcast(requiredLabels.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToList(x):\n",
    "    tempList=[]\n",
    "    for k, v in x.items():\n",
    "        tempList.append((k,v))\n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProbDoc(x,v):\n",
    "    tempDict={}\n",
    "    for label in labelsToUse.value[v]:\n",
    "        tempDict[label] = x\n",
    "    return tempDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbDocIndex = bagOfWords.zipWithIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbDoc = ProbDocIndex.map(lambda x: getProbDoc(x[0],x[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbDocList= ProbDoc.map(lambda x : dictToList(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbDocList = sc.parallelize(ProbDocList.reduce(add)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelWC = ProbDocList.map(lambda x: (x[0],len(x[1])))\n",
    "labelWordCount =sc.broadcast(labelWC.collectAsMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countWord2(x):\n",
    "    dictionary={}\n",
    "    for word in x[1]:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = 1\n",
    "        else:\n",
    "            dictionary[word] = dictionary[word]+1\n",
    "    return (x[0],dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ProbDocListCount = ProbDocList.map(lambda x: countWord2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAllwords(x):\n",
    "    tempDict=x[1]\n",
    "    for word in wordList.value:\n",
    "        if word not in x[1]:\n",
    "            tempDict[word] = 0\n",
    "    return (x[0],tempDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ProbDocListAll = ProbDocListCount.map(lambda x: addAllwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWordProbability(x):\n",
    "    tempDict={}\n",
    "    for k,v in x[1].items():\n",
    "        tempDict[k]= (v+1)/(numWords.value + labelWordCount.value[x[0]])\n",
    "    return (x[0],tempDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordProbability = ProbDocListAll.map(lambda x: getWordProbability(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLogProb(x):\n",
    "    tempDict= {}\n",
    "    for k,v in x[1].items():\n",
    "        tempDict[k] = math.log(v)\n",
    "    return (x[0],tempDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "logProbability = wordProbability.map(lambda x: getLogProb(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Class Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "classList = sc.parallelize(requiredLabels.reduce(add))\n",
    "classCount = classList.map(lambda x: (x,1)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classProbability = classCount.map(lambda x: (x[0],math.log(x[1]/numberOfDocs.value)))\n",
    "classProb = sc.broadcast(classProbability.collectAsMap())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0010483937106762\n"
     ]
    }
   ],
   "source": [
    "sums=0\n",
    "for k,v in wordProbability.collect()[3][1].items():\n",
    "    sums = sums+v\n",
    "print(sums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDocuments = sc.textFile(\"/home/vyom/UGA/DSP/Project1/X_test_small.txt\")\n",
    "testLabels = sc.textFile(\"y_test_small.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWordsTest = testDocuments.map(lambda word: word.lower().split())\n",
    "bagOfWordsTest = bagOfWordsTest.map(lambda x: stripWord(x))\n",
    "bagOfWordsTest = bagOfWordsTest.map(lambda x: stripStopWord(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = sc.broadcast(bagOfWordsTest.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestLogProbSum(x):\n",
    "    tempDict={}\n",
    "    for i in range(len(testData.value)):\n",
    "        logSum=0;\n",
    "        for word in testData.value[i]:\n",
    "            if word in x[1]:\n",
    "                logSum=logSum+x[1][word]\n",
    "            else:\n",
    "                logSum = logSum+ 1/numWords.value\n",
    "        tempDict[i]= logSum\n",
    "    return (x[0],tempDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "logProbSum = logProbability.map(lambda x: TestLogProbSum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(x):\n",
    "    tempDict={}\n",
    "    for k,v in x[1].items():\n",
    "        tempDict[k]= v+classProb.value[x[0]]\n",
    "    return(x[0],tempDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = logProbSum.map(lambda x: getPrediction(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictToTupple(x):\n",
    "    tempList=[]\n",
    "    for k, v in x[1].items():\n",
    "        tempList.append((k,(x[0],v)))\n",
    "    return tempList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictComparison = sc.parallelize(prediction.map(lambda x: dictToTupple(x)).reduce(add)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(x):\n",
    "    tempList = []\n",
    "    for i in x:\n",
    "        if type(i) == float:\n",
    "            tempList.append(i)\n",
    "    return x[tempList.index(max(tempList))*2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictedLabel = predictComparison.map(lambda x: getPrediction(x[1]))\n",
    "predicted = predictedLabel.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctLabel = testLabels.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9205378973105135\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(predicted)):\n",
    "    if predicted[i] in correctLabel[i]:\n",
    "        count = count+1\n",
    "accuracy = count/len(predicted)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = open('y_test_small_prediction.txt', 'w')\n",
    "for labels in predicted:\n",
    "    result.write(\"%s\\n\" % labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
